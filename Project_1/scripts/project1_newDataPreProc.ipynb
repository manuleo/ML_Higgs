{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from costs import *\n",
    "from lab_helpers import *\n",
    "from plots_lab4 import *\n",
    "from my_helpers import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do Graphs\n",
    "- PCA Decomposition + Classification\n",
    "- Correlation\n",
    "- Changing loss for different algorithms\n",
    "- ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do tasks\n",
    "- Manuel: implement K-fold to choose degree, change split data , ?\n",
    "- Gabbo: ?\n",
    "- Marco: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y_or, tX_or, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_or\n",
    "tX = tX_or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0       138.470                       51.655        97.827    27.980   \n",
       "1       160.937                       68.768       103.235    48.146   \n",
       "2      -999.000                      162.172       125.953    35.635   \n",
       "3       143.905                       81.417        80.943     0.414   \n",
       "4       175.864                       16.915       134.805    16.405   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                  0.91           124.711                2.666   \n",
       "1               -999.00          -999.000             -999.000   \n",
       "2               -999.00          -999.000             -999.000   \n",
       "3               -999.00          -999.000             -999.000   \n",
       "4               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\n",
       "0               3.064      41.928     197.760  ...       -0.277   \n",
       "1               3.473       2.078     125.157  ...       -1.916   \n",
       "2               3.148       9.336     197.814  ...       -2.186   \n",
       "3               3.310       0.414      75.968  ...        0.060   \n",
       "4               3.891      16.405      57.983  ...       -0.871   \n",
       "\n",
       "   PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "0        258.733            2              67.435                2.150   \n",
       "1        164.546            1              46.226                0.725   \n",
       "2        260.414            1              44.251                2.053   \n",
       "3         86.062            0            -999.000             -999.000   \n",
       "4         53.131            0            -999.000             -999.000   \n",
       "\n",
       "   PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                0.444                 46.062                    1.24   \n",
       "1                1.158               -999.000                 -999.00   \n",
       "2               -2.028               -999.000                 -999.00   \n",
       "3             -999.000               -999.000                 -999.00   \n",
       "4             -999.000               -999.000                 -999.00   \n",
       "\n",
       "   PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "0                  -2.475         113.497  \n",
       "1                -999.000          46.226  \n",
       "2                -999.000          44.251  \n",
       "3                -999.000           0.000  \n",
       "4                -999.000           0.000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_pd = pd.read_csv('../data/train.csv')\n",
    "tX_pd.drop(labels=['Id', 'Prediction'], axis=1, inplace=True)\n",
    "tX_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_pd0 = tX_pd[tX_pd['PRI_jet_num']==0]\n",
    "tX_pd1 = tX_pd[tX_pd['PRI_jet_num']==1]\n",
    "tX_pd2 = tX_pd[tX_pd['PRI_jet_num']==2]\n",
    "tX_pd3 = tX_pd[tX_pd['PRI_jet_num']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_pds = [tX_pd0, tX_pd1, tX_pd2, tX_pd3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet: 0\n",
      "26123 0 DER_mass_MMC\n",
      "99913 4 DER_deltaeta_jet_jet\n",
      "99913 5 DER_mass_jet_jet\n",
      "99913 6 DER_prodeta_jet_jet\n",
      "99913 12 DER_lep_eta_centrality\n",
      "99913 23 PRI_jet_leading_pt\n",
      "99913 24 PRI_jet_leading_eta\n",
      "99913 25 PRI_jet_leading_phi\n",
      "99913 26 PRI_jet_subleading_pt\n",
      "99913 27 PRI_jet_subleading_eta\n",
      "99913 28 PRI_jet_subleading_phi\n",
      "jet: 1\n",
      "7562 0 DER_mass_MMC\n",
      "77544 4 DER_deltaeta_jet_jet\n",
      "77544 5 DER_mass_jet_jet\n",
      "77544 6 DER_prodeta_jet_jet\n",
      "77544 12 DER_lep_eta_centrality\n",
      "77544 26 PRI_jet_subleading_pt\n",
      "77544 27 PRI_jet_subleading_eta\n",
      "77544 28 PRI_jet_subleading_phi\n",
      "jet: 2\n",
      "2952 0 DER_mass_MMC\n",
      "jet: 3\n",
      "1477 0 DER_mass_MMC\n"
     ]
    }
   ],
   "source": [
    "#searching for nulls:\n",
    "for jet in range (0, 4):\n",
    "    print (\"jet: {}\".format(jet))\n",
    "    i = 0\n",
    "    for c in tX_pds[jet]:\n",
    "        s = tx_pds[jet][tx_pds[jet][c] == -999].index.size\n",
    "        if s > 0:\n",
    "            print(s, i, c)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet: 0\n",
      "99913 22 PRI_jet_num\n",
      "99913 29 PRI_jet_all_pt\n",
      "jet: 1\n",
      "jet: 2\n",
      "9925 12 DER_lep_eta_centrality\n",
      "jet: 3\n",
      "5827 12 DER_lep_eta_centrality\n"
     ]
    }
   ],
   "source": [
    "#searching for zeros:\n",
    "for jet in range (0, 4):\n",
    "    print (\"jet: {}\".format(jet))\n",
    "    i = 0\n",
    "    for c in tX_pds[jet]:\n",
    "        s = tx_pds[jet][tx_pds[jet][c] == 0].index.size\n",
    "        if s > 1000:\n",
    "            print(s, i, c)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_pd=pd.DataFrame(tX)\n",
    "tX_pd0 = tX_pd[tX_pd[22]==0]\n",
    "tX_pd1 = tX_pd[tX_pd[22]==1]\n",
    "tX_pd2 = tX_pd[tX_pd[22]==2]\n",
    "tX_pd3 = tX_pd[tX_pd[22]==3]\n",
    "tX_pds = [tX_pd0, tX_pd1, tX_pd2, tX_pd3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops_0 = [4, 5, 6, 12, 23, 24, 25, 26, 27, 28, 29] # 29 all zeros\n",
    "drops_1 = [4, 5, 6, 12, 26, 27, 28]\n",
    "drop_22 = [22]\n",
    "tX_pds[0].drop(drops_0, axis=1, inplace=True)\n",
    "tX_pds[1].drop(drops_1, axis=1, inplace=True)\n",
    "for jet in range(0, 4):\n",
    "    tX_pds[jet].drop(drop_22, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet in range(0, 4):\n",
    "    tX_pd[jet].where(tX_pd[jet]!=-999, inplace=True)\n",
    "    tX_pd[jet].fillna(tX_pd[jet].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new0 = y[tX_pds[0].index.values]\n",
    "y_new1 = y[tX_pds[1].index.values]\n",
    "y_new2 = y[tX_pds[2].index.values]\n",
    "y_new3 = y[tX_pds[3].index.values]\n",
    "y_new = [y_new0, y_new1, y_new2, y_new3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_new0 = tX_pds[0].values\n",
    "tX_new1 = tX_pds[1].values\n",
    "tX_new2 = tX_pds[2].values\n",
    "tX_new3 = tX_pds[3].values\n",
    "tX_new = [tX_new0, tX_new1, tX_new2, tX_new3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids0 = tX_pds[0].index.values\n",
    "ids1 = tX_pds[1].index.values\n",
    "ids2 = tX_pds[2].index.values\n",
    "ids3 = tX_pds[3].index.values\n",
    "ids = [ids0, ids1, ids2, ids3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 18)\n",
      "(77544, 22)\n",
      "(50379, 29)\n",
      "(22164, 29)\n"
     ]
    }
   ],
   "source": [
    "for jet in range(0,4):\n",
    "    print(tX_new[jet].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = [], []\n",
    "for jet in range (0, 4):\n",
    "    tX_new[jet], mean, std = standardize(tX_new[jet])\n",
    "    means.append(mean)\n",
    "    stds.append(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet in range(0,4):\n",
    "    tX_new[jet] = np.c_[np.ones(tX_new[jet].shape[0]), tX_new[jet]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet in range(0,4):\n",
    "    xtr, xte, ytr, yte = split_data(y_new[jet],tX_new[jet],0.8,1)\n",
    "    x_tr.append(xtr)\n",
    "    x_te.append(xte)\n",
    "    y_tr.append(ytr)\n",
    "    y_te.append(yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Main Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree, mean=True):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    losses_tr = []\n",
    "    losses_te = []\n",
    "    \n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    for k_group in range(k):\n",
    "        index_te = k_indices[k_group]\n",
    "        index_tr = np.setdiff1d(np.arange(len(y)), index_te)\n",
    "        #print(index_te, index_tr)\n",
    "        x_te = x[index_te]\n",
    "        x_tr = x[index_tr]\n",
    "        y_te = y[index_te]\n",
    "        y_tr = y[index_tr]\n",
    "        \n",
    "        # form data with polynomial degree\n",
    "        x_te_poly = build_poly(x_te, degree)\n",
    "        x_tr_poly = build_poly(x_tr, degree)\n",
    "        \n",
    "        w = ridge_regression(y_tr, x_tr_poly, lambda_)\n",
    "        #w = least_squares(y_tr, x_tr_poly)\n",
    "        \n",
    "        # calculate the loss for train and test data\n",
    "        rmse_tr = compute_rmse(y_tr, x_tr_poly, w)\n",
    "        rmse_te = compute_rmse(y_te, x_te_poly, w)\n",
    "        #print(lambda_, rmse_te)\n",
    "        losses_tr.append(rmse_tr)\n",
    "        losses_te.append(rmse_te)\n",
    "        \n",
    "    if mean==True:\n",
    "        loss_tr = np.mean(losses_tr)\n",
    "        loss_te = np.mean(losses_te)\n",
    "    else:\n",
    "        loss_tr = losses_tr\n",
    "        loss_te = losses_te\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.798902580540896, 1.2203432524042486)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_indices = build_k_indices(y_tr[3], 8, 264)\n",
    "cross_validation(y_tr[3], x_tr[3], k_indices, 8, 0.0001, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7041252116104094\n",
      "0.7042380151968517\n",
      "0.7043858311412644\n",
      "0.7045655509762518\n",
      "0.7047672807923382\n",
      "0.7049790549845106\n",
      "0.7051946447681876\n",
      "0.7054184473396046\n",
      "0.7056628351943719\n",
      "0.7059388046287444\n",
      "0.7062465595118876\n",
      "0.7065741837557518\n",
      "0.7069059294338479\n",
      "0.707232715135369\n",
      "0.7075572125961525\n",
      "0.7078937138025636\n",
      "0.7082688136033688\n",
      "0.7087270491003984\n",
      "0.7093368031937478\n",
      "0.7101819731779753\n",
      "0.7113258732247854\n",
      "0.7127569089395003\n",
      "0.7143583440627039\n",
      "0.7159403949424944\n",
      "0.7173167203696103\n",
      "0.7183669817535696\n",
      "0.7190527250996134\n",
      "0.7194002067249817\n",
      "0.7194787529736388\n",
      "0.7193923662611028\n",
      "0.719288604483652\n",
      "0.7193789804774946\n",
      "0.7199607161784856\n",
      "0.7214342447110549\n",
      "0.7243093192111808\n",
      "0.7291563599607089\n",
      "0.7364281552459037\n",
      "0.74617729977841\n",
      "0.7579103056693146\n",
      "0.7708181794738949\n",
      "0.7842305010692168\n",
      "0.797850893148035\n",
      "0.8116115895702782\n",
      "0.825416151129492\n",
      "0.8390309122856741\n",
      "0.8521251845568565\n",
      "0.8643942659818447\n",
      "0.8757436641956786\n",
      "0.8864354912475741\n",
      "0.8970275062732881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cross_validation_demo():\n",
    "    degree = 3\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-8, 1, 50)\n",
    "#     for d in range (1, degree+1):\n",
    "#         for i in range (0, 3):\n",
    "    #seed = i\n",
    "    # split data in k fold\n",
    "    #y_sub, x_sub = get_subsample(y_tr, x_tr, 10000, seed)\n",
    "    seed = 1\n",
    "    k_indices = build_k_indices(y_tr[0], k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for lambda_ in lambdas:\n",
    "        loss_tr, loss_te = cross_validation(y_tr[0], x_tr[0], k_indices, k_fold, lambda_, degree)\n",
    "        #print(loss_te)\n",
    "        rmse_tr.append(loss_tr)\n",
    "        rmse_te.append(loss_te)\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te, degree)\n",
    "\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_degree(y, x, max_degree, k_fold, seed=1):\n",
    "    #y_sub, x_sub = get_subsample(y, x, 100000, seed)\n",
    "    lambdas = np.logspace(-4, -1, 20)\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    loss_min = np.inf\n",
    "    degree_star = 0\n",
    "    lambda_star = 0\n",
    "    for degree in range(1, max_degree+1):\n",
    "        for lambda_ in lambdas:\n",
    "            print(degree)\n",
    "            loss_tr, loss_te = cross_validation(y, x, k_indices, k_fold, lambda_, degree)\n",
    "            print(loss_te)\n",
    "            if loss_te < loss_min:\n",
    "                loss_min = loss_te\n",
    "                print(\"New loss: {}, degree: {}\".format(loss_te, degree))\n",
    "                degree_star = degree\n",
    "                lambda_star = lambda_\n",
    "    return degree_star, lambda_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0001 0.8471231725695323\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0001 0.848236186069115\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0001 0.8481566417487494\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0001 0.847348495381365\n",
      "0.8477161239421904\n",
      "New loss: 0.8477161239421904, degree: 1\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0001438449888287663 0.8496504008832181\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0001438449888287663 0.8507207629399898\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0001438449888287663 0.8507210873619652\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0001438449888287663 0.8499748414247055\n",
      "0.8502667731524697\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00020691380811147902 0.8520318256305315\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00020691380811147902 0.8530855641781513\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00020691380811147902 0.8531437442773783\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00020691380811147902 0.8524601462464619\n",
      "0.8526803200831307\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00029763514416313193 0.8542045995851405\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00029763514416313193 0.8552607164730565\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00029763514416313193 0.8553591113623273\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00029763514416313193 0.8547333034466312\n",
      "0.854889432716789\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00042813323987193956 0.856123410912383\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00042813323987193956 0.8571930305903517\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00042813323987193956 0.8573184498862924\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00042813323987193956 0.8567415012597973\n",
      "0.8568440981622061\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0006158482110660267 0.8577620613141919\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0006158482110660267 0.8588497468505554\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0006158482110660267 0.8589928109846496\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0006158482110660267 0.8584533743788835\n",
      "0.8585144983820701\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0008858667904100823 0.8591167910178069\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0008858667904100823 0.860222852893324\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0008858667904100823 0.8603770527289774\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0008858667904100823 0.8598627433491232\n",
      "0.8598948599973079\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0012742749857031334 0.8602074528092958\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0012742749857031334 0.8613300848996752\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0012742749857031334 0.8614908776403565\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0012742749857031334 0.8609891329216678\n",
      "0.8610043870677488\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0018329807108324356 0.8610747329721203\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0018329807108324356 0.8622113791443032\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0018329807108324356 0.8623754602326578\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0018329807108324356 0.8618739080823364\n",
      "0.8618838701078545\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0026366508987303583 0.8617753947212088\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0026366508987303583 0.8629232751878546\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0026366508987303583 0.8630879702728801\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0026366508987303583 0.8625745871790278\n",
      "0.8625903068402427\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00379269019073225 0.8623785962846913\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00379269019073225 0.8635345535116633\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00379269019073225 0.8636971149882575\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00379269019073225 0.8631606214623386\n",
      "0.8631927215617378\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.005455594781168515 0.862964288385621\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.005455594781168515 0.8641241558367807\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.005455594781168515 0.8642806198199263\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.005455594781168515 0.863711618680742\n",
      "0.8637701706807676\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.007847599703514606 0.8636218255516842\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.007847599703514606 0.8647795711405754\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.007847599703514606 0.8649228434669058\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.007847599703514606 0.8643160416989176\n",
      "0.8644100704645208\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.011288378916846883 0.8644459236001689\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.011288378916846883 0.8655929587038216\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.011288378916846883 0.8657102453922243\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.011288378916846883 0.8650674874425505\n",
      "0.8652041537846914\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.01623776739188721 0.8655301485691453\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.01623776739188721 0.8666553278080443\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.01623776739188721 0.866726070325989\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.01623776739188721 0.8660588609386864\n",
      "0.8662426019104662\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.023357214690901212 0.8669643112819095\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.023357214690901212 0.8680550418351829\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.023357214690901212 0.8680514995757915\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.023357214690901212 0.867380991369453\n",
      "0.8676129610155843\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.03359818286283781 0.8688445096944494\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.03359818286283781 0.8698888792662647\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.03359818286283781 0.8697809707724716\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.03359818286283781 0.8691342660867734\n",
      "0.8694121564549898\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.04832930238571752 0.8712955343311461\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.04832930238571752 0.8722846305842439\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.04832930238571752 0.8720481975623692\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.04832930238571752 0.8714522071753792\n",
      "0.8717701424132845\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.06951927961775606 0.8744885757773861\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.06951927961775606 0.8754177117469122\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.06951927961775606 0.8750429446168287\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.06951927961775606 0.8745188912375542\n",
      "0.8748670308446703\n",
      "1\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.1 0.8786271424648064\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.1 0.8794949929902858\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.1 0.878991338942513\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.1 0.8785526814775478\n",
      "0.8789165389687882\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0001 0.8248618494927841\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0001 0.8257584820559478\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0001 1.294407469007368\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0001 0.8237863257074234\n",
      "0.9422035315658809\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0001438449888287663 0.8269793609899198\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0001438449888287663 0.8277656622249148\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0001438449888287663 1.3072187090854113\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0001438449888287663 0.8259339614314981\n",
      "0.946974423432936\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00020691380811147902 0.8290782087941384\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00020691380811147902 0.829774207210554\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00020691380811147902 1.31945735751137\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00020691380811147902 0.8280746150120077\n",
      "0.9515960971320174\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00029763514416313193 0.8311040506300899\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00029763514416313193 0.8317347047494447\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00029763514416313193 1.3306173986804304\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00029763514416313193 0.8301539728395508\n",
      "0.9559025317248789\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00042813323987193956 0.8330074745300645\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00042813323987193956 0.8335988762089336\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00042813323987193956 1.34026759269841\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00042813323987193956 0.8321208057974275\n",
      "0.9597486873087089\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0006158482110660267 0.8347445303610103\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0006158482110660267 0.8353198713239832\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0006158482110660267 1.3480754066585807\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0006158482110660267 0.8339272410047639\n",
      "0.9630167623370844\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0008858667904100823 0.8362825520055481\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0008858667904100823 0.8368596368778433\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0008858667904100823 1.3538162488984173\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0008858667904100823 0.8355352045546021\n",
      "0.9656234105841026\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0012742749857031334 0.8376065989403457\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0012742749857031334 0.8381976058053946\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0012742749857031334 1.357324383441225\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0012742749857031334 0.8369238977058938\n",
      "0.9675131214732148\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0018329807108324356 0.8387243862179001\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0018329807108324356 0.8393372664259878\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0018329807108324356 1.3583811821656708\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0018329807108324356 0.838095118648959\n",
      "0.9686344883646294\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.0026366508987303583 0.8396693782735292\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.0026366508987303583 0.8403097117257464\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.0026366508987303583 1.3565667926937526\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.0026366508987303583 0.8390755182535715\n",
      "0.9689053502366499\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.00379269019073225 0.8405021887015492\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.00379269019073225 0.8411745298974989\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.00379269019073225 1.351110705619448\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.00379269019073225 0.8399164142570135\n",
      "0.9681759596188775\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.005455594781168515 0.8413108605397494\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.005455594781168515 0.8420191073200073\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.005455594781168515 1.3407878688654247\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.005455594781168515 0.8406931951330433\n",
      "0.9662027579645561\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.007847599703514606 0.8422107339929831\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.007847599703514606 0.8429574598720743\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.007847599703514606 1.323934186100242\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.007847599703514606 0.8415070468405474\n",
      "0.9626523567014618\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.011288378916846883 0.8433445947974512\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.011288378916846883 0.8441296551762245\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.011288378916846883 1.2986771080259338\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.011288378916846883 0.842491395263747\n",
      "0.9571606883158391\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.01623776739188721 0.8448841376272355\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.01623776739188721 0.8457033552163283\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.01623776739188721 1.2634502469684457\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.01623776739188721 0.8438236890925672\n",
      "0.9494653572261442\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.023357214690901212 0.8470326318074324\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.023357214690901212 0.8478777719015825\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.023357214690901212 1.2177654496815815\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.023357214690901212 0.8457380905954299\n",
      "0.9396034859965066\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.03359818286283781 0.8500229399866606\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.03359818286283781 0.8508837726333945\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.03359818286283781 1.1630715921974517\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.03359818286283781 0.8485253680173404\n",
      "0.9281259182087118\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.04832930238571752 0.8540965263862603\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.04832930238571752 0.8549641256276103\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.04832930238571752 1.1033472179015245\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.04832930238571752 0.8524982724431366\n",
      "0.916226535589633\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.06951927961775606 0.8594484570703504\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.06951927961775606 0.8603170765861056\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.06951927961775606 1.04487832293105\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.06951927961775606 0.8579074389127345\n",
      "0.9056378238750602\n",
      "2\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n",
      "0.1 0.866143472205496\n",
      "[137918  44085  82476 ... 157074  76245  75324] [     1      2      3 ... 187497 187498 187499]\n",
      "0.1 0.8670084988827991\n",
      "[116948 145481  57794 ...  12743  80472 129878] [     0      1      2 ... 187494 187496 187497]\n",
      "0.1 0.9947132852610833\n",
      "[ 55620 161981 162872 ...  54584 139536  19192] [     0      2      5 ... 187497 187498 187499]\n",
      "0.1 0.8648258618207656\n",
      "0.8981727795425359\n",
      "3\n",
      "[132804  89740  37022 ... 109134  30298 133442] [     0      1      3 ... 187496 187498 187499]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-442-6e87ddc16e75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_degree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mk_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdegree_star\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_best_degree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_degree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m165165623\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best degree: {} with lambda = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree_star\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-394-0e2910e25997>\u001b[0m in \u001b[0;36mselect_best_degree\u001b[1;34m(y, x, max_degree, k_fold, seed)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mloss_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss_te\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mloss_min\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-417-2071e44292f5>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, k_indices, k, lambda_, degree, mean)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# form data with polynomial degree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx_te_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mx_tr_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\EPFL\\ML\\github_mine\\ML\\Project_1\\scripts\\my_helpers.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[1;34m(x, degree)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mpsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mpsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_degree = 3\n",
    "k_fold = 4\n",
    "degree_star, lambda_star = select_best_degree(y_tr, x_tr, max_degree, k_fold, 165165623)\n",
    "print(\"Best degree: {} with lambda = {}\".format(degree_star, lambda_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_degree_ls(y, x, max_degree, k_fold, seed=1):\n",
    "    #y_sub, x_sub = get_subsample(y, x, 50000, seed)\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    loss_min = np.inf\n",
    "    degree_star = 0\n",
    "    lambda_star = 0\n",
    "    for degree in range(1, max_degree+1):\n",
    "        rmse_te = []\n",
    "        loss_tr, loss_te = cross_validation(y, x, k_indices, k_fold, 0, degree)\n",
    "        #print(degree, lambda_, loss_te)\n",
    "        if loss_te < loss_min:\n",
    "            loss_min = loss_te\n",
    "            print(\"New loss: {}, degree: {}\".format(loss_te, degree))\n",
    "            degree_star = degree\n",
    "    return degree_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New loss: 0.8352554444438645, degree: 1\n",
      "New loss: 0.8074198480959829, degree: 2\n",
      "New loss: 0.7970505329743582, degree: 3\n",
      "New loss: 0.7967003079401784, degree: 4\n",
      "Best degree for least squares: 4\n"
     ]
    }
   ],
   "source": [
    "max_degree = 10\n",
    "k_fold = 4\n",
    "degree_star_ls = select_best_degree_ls(y_tr, x_tr, max_degree, k_fold, 264)\n",
    "print(\"Best degree for least squares: {}\".format(degree_star_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    w = initial_w\n",
    "    loss = np.inf\n",
    "    for n_iter in range(max_iters):\n",
    "        g = compute_gradient(y, tx, w)\n",
    "        new_w = w - gamma*g;\n",
    "        new_loss = compute_loss(y, tx, new_w)\n",
    "        # print TO DELETE IN FINAL VERSION\n",
    "        if new_loss <= loss:\n",
    "            loss, w = new_loss, new_w\n",
    "            gamma *=1.8 #accelerate algorithm learning rate\n",
    "            #print(\"Gradient Descent({bi}/{ti}): loss={l} ; gamma={g}; gamma aumenta\".format(\n",
    "             # bi=n_iter, ti=max_iters - 1, l=loss, g= gamma))\n",
    "        else:\n",
    "            gamma *=0.3 #decelerate to avoid exponential growing\n",
    "            #print(\"Gradient Descent({bi}/{ti}): loss={l} ; gamma={g}; gamma diminuisce\".format(\n",
    "             # bi=n_iter, ti=max_iters - 1, l=loss, g= gamma)\n",
    "        print(\"Gradient Descent({bi}/{ti}): ||gradient||={grad}, loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, grad=np.linalg.norm(g), l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/199): ||gradient||=0.9198964473372747, loss=0.49991543478685996, w0=-3.1381702249274604e-05, w1=-1.870332018899931e-05\n",
      "Gradient Descent(1/199): ||gradient||=0.9186848945865361, loss=0.4997636980245322, w0=-8.78042153832626e-05, w1=-5.236507656267239e-05\n",
      "Gradient Descent(2/199): ||gradient||=0.9165086790795948, loss=0.4994921215723027, w0=-0.00018915591588298592, w1=-0.00011294257728487969\n",
      "Gradient Descent(3/199): ||gradient||=0.9126063083581455, loss=0.4990082616199879, w0=-0.000370914263529803, w1=-0.0002219378872869192\n",
      "Gradient Descent(4/199): ||gradient||=0.9056299309807633, loss=0.49815319084166065, w0=-0.0006959041130019329, w1=-0.00041798666987893115\n",
      "Gradient Descent(5/199): ||gradient||=0.8932269289430593, loss=0.49666407351067016, w0=-0.0012739014639035493, w1=-0.0007704142328603178\n",
      "Gradient Descent(6/199): ||gradient||=0.8713980371643467, loss=0.49413764114400255, w0=-0.002292032255140569, w1=-0.0014033062129404496\n",
      "Gradient Descent(7/199): ||gradient||=0.8336914854870378, loss=0.49004496000892644, w0=-0.004054621864207936, w1=-0.0025378020652307696\n",
      "Gradient Descent(8/199): ||gradient||=0.7708210576370715, loss=0.48392417182397535, w0=-0.007012143781032614, w1=-0.0045650758007922156\n",
      "Gradient Descent(9/199): ||gradient||=0.6730593787686956, loss=0.4758746897312079, w0=-0.011703585013512112, w1=-0.008168591631344086\n",
      "Gradient Descent(10/199): ||gradient||=0.5420469001358224, loss=0.4668314646613726, w0=-0.018440239398187373, w1=-0.014520131670101091\n",
      "Gradient Descent(11/199): ||gradient||=0.417585276699318, loss=0.45684219087207145, w0=-0.0266511349012321, w1=-0.02557881435937765\n",
      "Gradient Descent(12/199): ||gradient||=0.34951950406858123, loss=0.4441675056514142, w0=-0.03507313894297936, w1=-0.044530615642647674\n",
      "Gradient Descent(13/199): ||gradient||=0.2802581748299309, loss=0.4305010778316688, w0=-0.044834692707357696, w1=-0.07630731446605377\n",
      "Gradient Descent(14/199): ||gradient||=0.19933661937191804, loss=0.4194261493875751, w0=-0.0433225318650242, w1=-0.12709402240381473\n",
      "Gradient Descent(15/199): ||gradient||=0.2126484850736893, loss=0.4194261493875751, w0=-0.0433225318650242, w1=-0.12709402240381473\n",
      "Gradient Descent(16/199): ||gradient||=0.2126484850736893, loss=0.4192164175189965, w0=-0.04417546498101249, w1=-0.15057107585432739\n",
      "Gradient Descent(17/199): ||gradient||=0.41005196201736743, loss=0.4192164175189965, w0=-0.04417546498101249, w1=-0.15057107585432739\n",
      "Gradient Descent(18/199): ||gradient||=0.41005196201736743, loss=0.4161425994149832, w0=-0.03042881057717925, w1=-0.16207735779908952\n",
      "Gradient Descent(19/199): ||gradient||=0.3562131324819593, loss=0.4161425994149832, w0=-0.03042881057717925, w1=-0.16207735779908952\n",
      "Gradient Descent(20/199): ||gradient||=0.3562131324819593, loss=0.4119259421855884, w0=-0.03309942831257582, w1=-0.16844869171449792\n",
      "Gradient Descent(21/199): ||gradient||=0.12649027507232175, loss=0.41025030347357094, w0=-0.029575140439970622, w1=-0.17946578929166102\n",
      "Gradient Descent(22/199): ||gradient||=0.12292495119423105, loss=0.40743339281067326, w0=-0.023442494523926122, w1=-0.19876354675726643\n",
      "Gradient Descent(23/199): ||gradient||=0.11680132506627634, loss=0.4029471327448956, w0=-0.01278468241212367, w1=-0.23182458833403902\n",
      "Gradient Descent(24/199): ||gradient||=0.10674668689952199, loss=0.3965790516938806, w0=0.0032309313983773826, w1=-0.2863021479535607\n",
      "Gradient Descent(25/199): ||gradient||=0.11037853434564666, loss=0.3965790516938806, w0=0.0032309313983773826, w1=-0.2863021479535607\n",
      "Gradient Descent(26/199): ||gradient||=0.11037853434564666, loss=0.3964684701806759, w0=0.015448328414554098, w1=-0.31109478735450924\n",
      "Gradient Descent(27/199): ||gradient||=0.30949111243344546, loss=0.3964684701806759, w0=0.015448328414554098, w1=-0.31109478735450924\n",
      "Gradient Descent(28/199): ||gradient||=0.30949111243344546, loss=0.3964684701806759, w0=0.015448328414554098, w1=-0.31109478735450924\n",
      "Gradient Descent(29/199): ||gradient||=0.30949111243344546, loss=0.3934972452046127, w0=0.012645111284258674, w1=-0.3149399904670085\n",
      "Gradient Descent(30/199): ||gradient||=0.08518921631593725, loss=0.3928422773768506, w0=0.01390331604737596, w1=-0.3215594212339835\n",
      "Gradient Descent(31/199): ||gradient||=0.08143325683778938, loss=0.39176458577149614, w0=0.01769426852847459, w1=-0.333137608291744\n",
      "Gradient Descent(32/199): ||gradient||=0.08261374022271092, loss=0.3904851713208589, w0=0.020707710599576625, w1=-0.3532046313023332\n",
      "Gradient Descent(33/199): ||gradient||=0.15244231978895387, loss=0.3904851713208589, w0=0.020707710599576625, w1=-0.3532046313023332\n",
      "Gradient Descent(34/199): ||gradient||=0.15244231978895387, loss=0.3904851713208589, w0=0.020707710599576625, w1=-0.3532046313023332\n",
      "Gradient Descent(35/199): ||gradient||=0.15244231978895387, loss=0.38970194899647265, w0=0.023115513292314566, w1=-0.35613896221101615\n",
      "Gradient Descent(36/199): ||gradient||=0.07231686370955237, loss=0.38924702709110287, w0=0.024867215085094988, w1=-0.36144019878751626\n",
      "Gradient Descent(37/199): ||gradient||=0.0693800954973171, loss=0.3884863243303348, w0=0.026866841411884168, w1=-0.3708048228655269\n",
      "Gradient Descent(38/199): ||gradient||=0.06849694468173842, loss=0.38737654415708406, w0=0.032221443986200235, w1=-0.38691647993837636\n",
      "Gradient Descent(39/199): ||gradient||=0.09598461127388905, loss=0.38737654415708406, w0=0.032221443986200235, w1=-0.38691647993837636\n",
      "Gradient Descent(40/199): ||gradient||=0.09598461127388905, loss=0.38709755946614643, w0=0.031409639884593415, w1=-0.39510299988579783\n",
      "Gradient Descent(41/199): ||gradient||=0.1410714760751551, loss=0.38709755946614643, w0=0.031409639884593415, w1=-0.39510299988579783\n",
      "Gradient Descent(42/199): ||gradient||=0.1410714760751551, loss=0.3864215399793017, w0=0.0350727177951097, w1=-0.39921296841299686\n",
      "Gradient Descent(43/199): ||gradient||=0.08456831532148283, loss=0.38609283928743754, w0=0.034597824755885076, w1=-0.4066886332281262\n",
      "Gradient Descent(44/199): ||gradient||=0.11635687063747818, loss=0.38609283928743754, w0=0.034597824755885076, w1=-0.4066886332281262\n",
      "Gradient Descent(45/199): ||gradient||=0.11635687063747818, loss=0.3855801463907678, w0=0.037564023270261745, w1=-0.4104639083541116\n",
      "Gradient Descent(46/199): ||gradient||=0.07098725686300805, loss=0.38521117682227085, w0=0.03758284187875093, w1=-0.4172961953261667\n",
      "Gradient Descent(47/199): ||gradient||=0.08865280508918541, loss=0.38521117682227085, w0=0.03758284187875093, w1=-0.4172961953261667\n",
      "Gradient Descent(48/199): ||gradient||=0.08865280508918541, loss=0.38485406384997894, w0=0.0397988301803087, w1=-0.4207754388932331\n",
      "Gradient Descent(49/199): ||gradient||=0.05956788893440248, loss=0.38448192908571455, w0=0.0402881948329062, w1=-0.4270292492982512\n",
      "Gradient Descent(50/199): ||gradient||=0.06633820597340725, loss=0.38442089464413837, w0=0.04551447515592648, w1=-0.43773687255237875\n",
      "Gradient Descent(51/199): ||gradient||=0.15761065003057645, loss=0.38442089464413837, w0=0.04551447515592648, w1=-0.43773687255237875\n",
      "Gradient Descent(52/199): ||gradient||=0.15761065003057645, loss=0.38442089464413837, w0=0.04551447515592648, w1=-0.43773687255237875\n",
      "Gradient Descent(53/199): ||gradient||=0.15761065003057645, loss=0.38370536779400194, w0=0.044360770783240404, w1=-0.4394259860437441\n",
      "Gradient Descent(54/199): ||gradient||=0.06222099110230357, loss=0.38348800700174634, w0=0.044301326033474996, w1=-0.44236759427566763\n",
      "Gradient Descent(55/199): ||gradient||=0.04860668539425892, loss=0.383189073110083, w0=0.04591786180813736, w1=-0.4475058466448936\n",
      "Gradient Descent(56/199): ||gradient||=0.04885484002764845, loss=0.38276849340828356, w0=0.04693068305756577, w1=-0.45650588328763114\n",
      "Gradient Descent(57/199): ||gradient||=0.07218281893711131, loss=0.38276849340828356, w0=0.04693068305756577, w1=-0.45650588328763114\n",
      "Gradient Descent(58/199): ||gradient||=0.07218281893711131, loss=0.3825873718960974, w0=0.0498284052981392, w1=-0.46099331139984334\n",
      "Gradient Descent(59/199): ||gradient||=0.0865949367220621, loss=0.3825873718960974, w0=0.0498284052981392, w1=-0.46099331139984334\n",
      "Gradient Descent(60/199): ||gradient||=0.0865949367220621, loss=0.38229970311486866, w0=0.04905354484341635, w1=-0.4634154097612027\n",
      "Gradient Descent(61/199): ||gradient||=0.045554523575472565, loss=0.38208015281211827, w0=0.05059222337498455, w1=-0.46760109124772614\n",
      "Gradient Descent(62/199): ||gradient||=0.046707216525688364, loss=0.38183039129040586, w0=0.05093771047973362, w1=-0.47497826544308125\n",
      "Gradient Descent(63/199): ||gradient||=0.08067338628463173, loss=0.38183039129040586, w0=0.05093771047973362, w1=-0.47497826544308125\n",
      "Gradient Descent(64/199): ||gradient||=0.08067338628463173, loss=0.3816990151389566, w0=0.05392994899937147, w1=-0.47864293097104027\n",
      "Gradient Descent(65/199): ||gradient||=0.09181351733579902, loss=0.3816990151389566, w0=0.05392994899937147, w1=-0.47864293097104027\n",
      "Gradient Descent(66/199): ||gradient||=0.09181351733579902, loss=0.38140101837396745, w0=0.052993763875687355, w1=-0.48064650178588253\n",
      "Gradient Descent(67/199): ||gradient||=0.040172136024456635, loss=0.38123091391261776, w0=0.05420974414245746, w1=-0.48409726949739024\n",
      "Gradient Descent(68/199): ||gradient||=0.04011639835467928, loss=0.3809951674469164, w0=0.05467020818561967, w1=-0.4901830876387525\n",
      "Gradient Descent(69/199): ||gradient||=0.0587199843578713, loss=0.3809951674469164, w0=0.05467020818561967, w1=-0.4901830876387525\n",
      "Gradient Descent(70/199): ||gradient||=0.0587199843578713, loss=0.3808561671034156, w0=0.056712761214752244, w1=-0.4932358728465866\n",
      "Gradient Descent(71/199): ||gradient||=0.06065901120024391, loss=0.3808561671034156, w0=0.056712761214752244, w1=-0.4932358728465866\n",
      "Gradient Descent(72/199): ||gradient||=0.06065901120024391, loss=0.38070675484703786, w0=0.05629675863399411, w1=-0.4948880697081792\n",
      "Gradient Descent(73/199): ||gradient||=0.03437710169565648, loss=0.3805724543076369, w0=0.05709337174035709, w1=-0.4977650896919669\n",
      "Gradient Descent(74/199): ||gradient||=0.03371872029255384, loss=0.380347504802962, w0=0.057923161002275445, w1=-0.502821417967265\n",
      "Gradient Descent(75/199): ||gradient||=0.0353360741618754, loss=0.3801552624788844, w0=0.06117016381868622, w1=-0.5114152905216629\n",
      "Gradient Descent(76/199): ||gradient||=0.0868549972476703, loss=0.3801552624788844, w0=0.06117016381868622, w1=-0.5114152905216629\n",
      "Gradient Descent(77/199): ||gradient||=0.0868549972476703, loss=0.3801552624788844, w0=0.06117016381868622, w1=-0.5114152905216629\n",
      "Gradient Descent(78/199): ||gradient||=0.0868549972476703, loss=0.37990446055546606, w0=0.06025622386799663, w1=-0.512732449768847\n",
      "Gradient Descent(79/199): ||gradient||=0.03013797122742819, loss=0.3798059156030959, w0=0.06086479596353714, w1=-0.5149947769707354\n",
      "Gradient Descent(80/199): ||gradient||=0.029582646754048075, loss=0.3796377325021035, w0=0.06155759036056807, w1=-0.5189768598962371\n",
      "Gradient Descent(81/199): ||gradient||=0.02988603821652102, loss=0.3794139288338467, w0=0.06382969816757092, w1=-0.5257836738330686\n",
      "Gradient Descent(82/199): ||gradient||=0.05385331845836831, loss=0.3794139288338467, w0=0.06382969816757092, w1=-0.5257836738330686\n",
      "Gradient Descent(83/199): ||gradient||=0.05385331845836831, loss=0.3794139288338467, w0=0.06382969816757092, w1=-0.5257836738330686\n",
      "Gradient Descent(84/199): ||gradient||=0.05385331845836831, loss=0.37930748989144936, w0=0.06340685859282029, w1=-0.5268228016896819\n",
      "Gradient Descent(85/199): ||gradient||=0.026807087764073437, loss=0.379232343212017, w0=0.06379460699418472, w1=-0.5286305900589766\n",
      "Gradient Descent(86/199): ||gradient||=0.026429755894928714, loss=0.37910158102876307, w0=0.06449936504431049, w1=-0.5318081753946006\n",
      "Gradient Descent(87/199): ||gradient||=0.025779232451409895, loss=0.37887998603582906, w0=0.06565536813188565, w1=-0.5372914115868667\n",
      "Gradient Descent(88/199): ||gradient||=0.02479156357937694, loss=0.37853558176716484, w0=0.06800696343269726, w1=-0.5464117445901066\n",
      "Gradient Descent(89/199): ||gradient||=0.03258988562878005, loss=0.37853558176716484, w0=0.06800696343269726, w1=-0.5464117445901066\n",
      "Gradient Descent(90/199): ||gradient||=0.03258988562878005, loss=0.37853558176716484, w0=0.06800696343269726, w1=-0.5464117445901066\n",
      "Gradient Descent(91/199): ||gradient||=0.03258988562878005, loss=0.37847536538605114, w0=0.06774134339187216, w1=-0.5477141177050802\n",
      "Gradient Descent(92/199): ||gradient||=0.027738362406501706, loss=0.3784081137173264, w0=0.06891401614328861, w1=-0.5499543441431679\n",
      "Gradient Descent(93/199): ||gradient||=0.03951405284074884, loss=0.3784081137173264, w0=0.06891401614328861, w1=-0.5499543441431679\n",
      "Gradient Descent(94/199): ||gradient||=0.03951405284074884, loss=0.37834206727202646, w0=0.06842349019205861, w1=-0.5511561942990433\n",
      "Gradient Descent(95/199): ||gradient||=0.0304225158131295, loss=0.3782950369307274, w0=0.06974234133756098, w1=-0.5532027831040229\n",
      "Gradient Descent(96/199): ||gradient||=0.046421773810511664, loss=0.3782950369307274, w0=0.06974234133756098, w1=-0.5532027831040229\n",
      "Gradient Descent(97/199): ||gradient||=0.046421773810511664, loss=0.3782192101919261, w0=0.06906497913554238, w1=-0.5543145897328704\n",
      "Gradient Descent(98/199): ||gradient||=0.03256348800089378, loss=0.3781863625212313, w0=0.0704641466114305, w1=-0.5561901419642732\n",
      "Gradient Descent(99/199): ||gradient||=0.05053199788292059, loss=0.3781863625212313, w0=0.0704641466114305, w1=-0.5561901419642732\n",
      "Gradient Descent(100/199): ||gradient||=0.05053199788292059, loss=0.37810265907289226, w0=0.06968905597825942, w1=-0.5572191567845676\n",
      "Gradient Descent(101/199): ||gradient||=0.032866606098295975, loss=0.3780730239484249, w0=0.07106101099049744, w1=-0.5589450864985751\n",
      "Gradient Descent(102/199): ||gradient||=0.049904511233416445, loss=0.3780730239484249, w0=0.07106101099049744, w1=-0.5589450864985751\n",
      "Gradient Descent(103/199): ||gradient||=0.049904511233416445, loss=0.37799031022315804, w0=0.07030697705295337, w1=-0.5598962692587653\n",
      "Gradient Descent(104/199): ||gradient||=0.030864528540993398, loss=0.3779543503641231, w0=0.07153774920247563, w1=-0.5614919833996477\n",
      "Gradient Descent(105/199): ||gradient||=0.044474850521653266, loss=0.3779543503641231, w0=0.07153774920247563, w1=-0.5614919833996477\n",
      "Gradient Descent(106/199): ||gradient||=0.044474850521653266, loss=0.3778831177632533, w0=0.0709143275158598, w1=-0.5623694962267904\n",
      "Gradient Descent(107/199): ||gradient||=0.02725555397893965, loss=0.37783808449301604, w0=0.07192419161530243, w1=-0.5638513332719829\n",
      "Gradient Descent(108/199): ||gradient||=0.036174660635675905, loss=0.37783808449301604, w0=0.07192419161530243, w1=-0.5638513332719829\n",
      "Gradient Descent(109/199): ||gradient||=0.036174660635675905, loss=0.3777832329470302, w0=0.07149562027576611, w1=-0.5646599120664837\n",
      "Gradient Descent(110/199): ||gradient||=0.023491643257352396, loss=0.37773234827744734, w0=0.0722626339272173, w1=-0.5660406117723381\n",
      "Gradient Descent(111/199): ||gradient||=0.02798541531932825, loss=0.37773234827744734, w0=0.0722626339272173, w1=-0.5660406117723381\n",
      "Gradient Descent(112/199): ||gradient||=0.02798541531932825, loss=0.37769151450075156, w0=0.07203435972166758, w1=-0.5667861513379303\n",
      "Gradient Descent(113/199): ||gradient||=0.020796448379199806, loss=0.3776393572545536, w0=0.07258948801176464, w1=-0.568075243409437\n",
      "Gradient Descent(114/199): ||gradient||=0.02232622559275806, loss=0.377588333501605, w0=0.07236360170695846, w1=-0.5703726024359062\n",
      "Gradient Descent(115/199): ||gradient||=0.044569960234299495, loss=0.377588333501605, w0=0.07236360170695846, w1=-0.5703726024359062\n",
      "Gradient Descent(116/199): ||gradient||=0.044569960234299495, loss=0.37758811354171706, w0=0.07398697827662784, w1=-0.571494113123698\n",
      "Gradient Descent(117/199): ||gradient||=0.06049611094726945, loss=0.37758811354171706, w0=0.07398697827662784, w1=-0.571494113123698\n",
      "Gradient Descent(118/199): ||gradient||=0.06049611094726945, loss=0.3774734104704165, w0=0.07307154647503165, w1=-0.5721438415511358\n",
      "Gradient Descent(119/199): ||gradient||=0.02560307349675981, loss=0.37743437097577587, w0=0.07389537252526818, w1=-0.5732146504634791\n",
      "Gradient Descent(120/199): ||gradient||=0.030235195825791275, loss=0.37743437097577587, w0=0.07389537252526818, w1=-0.5732146504634791\n",
      "Gradient Descent(121/199): ||gradient||=0.030235195825791275, loss=0.3773936500349805, w0=0.0735942921530556, w1=-0.5738034701868857\n",
      "Gradient Descent(122/199): ||gradient||=0.01930338988021067, loss=0.3773502513239982, w0=0.07402822791850343, w1=-0.5748167485368086\n",
      "Gradient Descent(123/199): ||gradient||=0.019883352701387243, loss=0.3772907352516291, w0=0.07393681984074807, w1=-0.5766266491602585\n",
      "Gradient Descent(124/199): ||gradient||=0.03180432497976459, loss=0.3772907352516291, w0=0.07393681984074807, w1=-0.5766266491602585\n",
      "Gradient Descent(125/199): ||gradient||=0.03180432497976459, loss=0.3772601111394095, w0=0.07496055740277986, w1=-0.5775270322925545\n",
      "Gradient Descent(126/199): ||gradient||=0.0368369701461698, loss=0.3772601111394095, w0=0.07496055740277986, w1=-0.5775270322925545\n",
      "Gradient Descent(127/199): ||gradient||=0.0368369701461698, loss=0.3772087103489772, w0=0.07452601579779915, w1=-0.5780354108422809\n",
      "Gradient Descent(128/199): ||gradient||=0.018672376155633576, loss=0.3771703336844059, w0=0.07491495902096323, w1=-0.5789005133364988\n",
      "Gradient Descent(129/199): ||gradient||=0.01894887411582462, loss=0.37711429272072133, w0=0.07484020252240821, w1=-0.580450552171511\n",
      "Gradient Descent(130/199): ||gradient||=0.027883181430691767, loss=0.37711429272072133, w0=0.07484020252240821, w1=-0.580450552171511\n",
      "Gradient Descent(131/199): ||gradient||=0.027883181430691767, loss=0.37708121348388723, w0=0.07566085878362429, w1=-0.5812272244984843\n",
      "Gradient Descent(132/199): ||gradient||=0.029631455078381125, loss=0.37708121348388723, w0=0.07566085878362429, w1=-0.5812272244984843\n",
      "Gradient Descent(133/199): ||gradient||=0.029631455078381125, loss=0.37704490546502617, w0=0.07536964604927561, w1=-0.5816628169500092\n",
      "Gradient Descent(134/199): ||gradient||=0.01724997691647665, loss=0.3770105401718543, w0=0.07562881667941775, w1=-0.5824123704142081\n",
      "Gradient Descent(135/199): ||gradient||=0.017165877881501656, loss=0.37695177088913756, w0=0.07574484702850508, w1=-0.5837476546228534\n",
      "Gradient Descent(136/199): ||gradient||=0.01899421714878402, loss=0.37692148570562073, w0=0.07710169262791508, w1=-0.5860316206865467\n",
      "Gradient Descent(137/199): ||gradient||=0.054220090727918, loss=0.37692148570562073, w0=0.07710169262791508, w1=-0.5860316206865467\n",
      "Gradient Descent(138/199): ||gradient||=0.054220090727918, loss=0.37692148570562073, w0=0.07710169262791508, w1=-0.5860316206865467\n",
      "Gradient Descent(139/199): ||gradient||=0.054220090727918, loss=0.37682644524415465, w0=0.07640556694575028, w1=-0.5864102724253792\n",
      "Gradient Descent(140/199): ||gradient||=0.016650580776069446, loss=0.3767965645111003, w0=0.07664467148671401, w1=-0.5870356600147364\n",
      "Gradient Descent(141/199): ||gradient||=0.016501858917438078, loss=0.376745477937799, w0=0.07671846419935624, w1=-0.5881547717783094\n",
      "Gradient Descent(142/199): ||gradient||=0.01816804164140217, loss=0.37671160786478297, w0=0.07790088351724668, w1=-0.5900751936992078\n",
      "Gradient Descent(143/199): ||gradient||=0.04825610442092132, loss=0.37671160786478297, w0=0.07790088351724668, w1=-0.5900751936992078\n",
      "Gradient Descent(144/199): ||gradient||=0.04825610442092132, loss=0.37671160786478297, w0=0.07790088351724668, w1=-0.5900751936992078\n",
      "Gradient Descent(145/199): ||gradient||=0.04825610442092132, loss=0.3766356523318643, w0=0.07732128008506954, w1=-0.5903961372206211\n",
      "Gradient Descent(146/199): ||gradient||=0.01563931340254658, loss=0.3766094801974734, w0=0.07745336774852776, w1=-0.5909299030113423\n",
      "Gradient Descent(147/199): ||gradient||=0.01555626373968682, loss=0.37656297807301164, w0=0.07763617808606241, w1=-0.5918788948154293\n",
      "Gradient Descent(148/199): ||gradient||=0.015451985463614959, loss=0.3764819326011553, w0=0.07809347822581313, w1=-0.5935397672728017\n",
      "Gradient Descent(149/199): ||gradient||=0.016210974608243976, loss=0.37642885163632395, w0=0.0778620860907724, w1=-0.5964324994905928\n",
      "Gradient Descent(150/199): ||gradient||=0.0572020732177142, loss=0.37642885163632395, w0=0.0778620860907724, w1=-0.5964324994905928\n",
      "Gradient Descent(151/199): ||gradient||=0.0572020732177142, loss=0.37642885163632395, w0=0.0778620860907724, w1=-0.5964324994905928\n",
      "Gradient Descent(152/199): ||gradient||=0.0572020732177142, loss=0.3763639979162107, w0=0.07928178781519514, w1=-0.596816759315354\n",
      "Gradient Descent(153/199): ||gradient||=0.04260833075213723, loss=0.3763639979162107, w0=0.07928178781519514, w1=-0.596816759315354\n",
      "Gradient Descent(154/199): ||gradient||=0.04260833075213723, loss=0.37630531695231634, w0=0.0788118352881565, w1=-0.5970633924846425\n",
      "Gradient Descent(155/199): ||gradient||=0.014908211767569006, loss=0.3762840666377174, w0=0.0788347473226203, w1=-0.5974755644658697\n",
      "Gradient Descent(156/199): ||gradient||=0.014708048925549026, loss=0.3762467257517887, w0=0.07906897984336392, w1=-0.5982031234845887\n",
      "Gradient Descent(157/199): ||gradient||=0.014963885063396522, loss=0.3761879108136801, w0=0.0790578901510292, w1=-0.5995025608408782\n",
      "Gradient Descent(158/199): ||gradient||=0.021972572186543523, loss=0.3761879108136801, w0=0.0790578901510292, w1=-0.5995025608408782\n",
      "Gradient Descent(159/199): ||gradient||=0.021972572186543523, loss=0.3761751577223521, w0=0.07988198597230842, w1=-0.6001532477635246\n",
      "Gradient Descent(160/199): ||gradient||=0.03521861893866122, loss=0.3761751577223521, w0=0.07988198597230842, w1=-0.6001532477635246\n",
      "Gradient Descent(161/199): ||gradient||=0.03521861893866122, loss=0.3761362201008082, w0=0.07924611088708965, w1=-0.6005349176900081\n",
      "Gradient Descent(162/199): ||gradient||=0.02351622446106723, loss=0.376127928882764, w0=0.08012627017357933, w1=-0.601147868777882\n",
      "Gradient Descent(163/199): ||gradient||=0.03747859183540602, loss=0.376127928882764, w0=0.08012627017357933, w1=-0.601147868777882\n",
      "Gradient Descent(164/199): ||gradient||=0.03747859183540602, loss=0.3760848467338232, w0=0.07945208937262828, w1=-0.6015121960900223\n",
      "Gradient Descent(165/199): ||gradient||=0.023370968435216157, loss=0.3760749662363606, w0=0.08030091303119544, w1=-0.6020933245359191\n",
      "Gradient Descent(166/199): ||gradient||=0.03591853609344955, loss=0.3760749662363606, w0=0.08030091303119544, w1=-0.6020933245359191\n",
      "Gradient Descent(167/199): ||gradient||=0.03591853609344955, loss=0.37603359618573673, w0=0.07967763478331942, w1=-0.6024388052305133\n",
      "Gradient Descent(168/199): ||gradient||=0.021481809200450213, loss=0.3760179930355585, w0=0.08041278478105703, w1=-0.6029935134188872\n",
      "Gradient Descent(169/199): ||gradient||=0.030995904539739747, loss=0.3760179930355585, w0=0.08041278478105703, w1=-0.6029935134188872\n",
      "Gradient Descent(170/199): ||gradient||=0.030995904539739747, loss=0.3759837423493009, w0=0.07991361406706003, w1=-0.6033190135612887\n",
      "Gradient Descent(171/199): ||gradient||=0.018635502628599573, loss=0.3759622996612751, w0=0.08048599604528822, w1=-0.603851288825571\n",
      "Gradient Descent(172/199): ||gradient||=0.0245163904254113, loss=0.3759622996612751, w0=0.08048599604528822, w1=-0.603851288825571\n",
      "Gradient Descent(173/199): ||gradient||=0.0245163904254113, loss=0.3759366863297597, w0=0.08014500940912765, w1=-0.6041568478334536\n",
      "Gradient Descent(174/199): ||gradient||=0.01599958312904941, loss=0.3759118922941351, w0=0.08055016261254995, w1=-0.6046689176895607\n",
      "Gradient Descent(175/199): ||gradient||=0.018751655043872835, loss=0.3759118922941351, w0=0.08055016261254995, w1=-0.6046689176895607\n",
      "Gradient Descent(176/199): ||gradient||=0.018751655043872835, loss=0.3758928304184189, w0=0.0803586612622116, w1=-0.6049558909348881\n",
      "Gradient Descent(177/199): ||gradient||=0.014338863123069666, loss=0.3758671970659703, w0=0.08062719990283188, w1=-0.6054485791833413\n",
      "Gradient Descent(178/199): ||gradient||=0.015200543414685935, loss=0.37583654449523124, w0=0.08036489072717935, w1=-0.6063504997897442\n",
      "Gradient Descent(179/199): ||gradient||=0.027969392552206655, loss=0.37583654449523124, w0=0.08036489072717935, w1=-0.6063504997897442\n",
      "Gradient Descent(180/199): ||gradient||=0.027969392552206655, loss=0.37582886080109595, w0=0.08128370285356662, w1=-0.6067923065577789\n",
      "Gradient Descent(181/199): ||gradient||=0.036968997621708515, loss=0.37582886080109595, w0=0.08128370285356662, w1=-0.6067923065577789\n",
      "Gradient Descent(182/199): ||gradient||=0.036968997621708515, loss=0.375783531496386, w0=0.08070975465583485, w1=-0.6070644065150398\n",
      "Gradient Descent(183/199): ||gradient||=0.0167182053280009, loss=0.3757620984584493, w0=0.08113419016175932, w1=-0.607502584441539\n",
      "Gradient Descent(184/199): ||gradient||=0.018986866136306145, loss=0.3757620984584493, w0=0.08113419016175932, w1=-0.607502584441539\n",
      "Gradient Descent(185/199): ||gradient||=0.018986866136306145, loss=0.3757441578195452, w0=0.08094097589901549, w1=-0.6077511395045695\n",
      "Gradient Descent(186/199): ||gradient||=0.013572183029778981, loss=0.37572153696885513, w0=0.08114010120247711, w1=-0.6081779108393255\n",
      "Gradient Descent(187/199): ||gradient||=0.013800818079967348, loss=0.3756860696494606, w0=0.08103313705429466, w1=-0.6089548792538191\n",
      "Gradient Descent(188/199): ||gradient||=0.019086297838013175, loss=0.3756860696494606, w0=0.08103313705429466, w1=-0.6089548792538191\n",
      "Gradient Descent(189/199): ||gradient||=0.019086297838013175, loss=0.3756670862808575, w0=0.08154565511964693, w1=-0.6093486850629586\n",
      "Gradient Descent(190/199): ||gradient||=0.02127896202154825, loss=0.3756670862808575, w0=0.08154565511964693, w1=-0.6093486850629586\n",
      "Gradient Descent(191/199): ||gradient||=0.02127896202154825, loss=0.3756473456718056, w0=0.08130696324519089, w1=-0.6095769393921033\n",
      "Gradient Descent(192/199): ||gradient||=0.013232837805350147, loss=0.3756267043461724, w0=0.08148075967979389, w1=-0.6099657476358593\n",
      "Gradient Descent(193/199): ||gradient||=0.013302247084608905, loss=0.3755926910253041, w0=0.08141711577151617, w1=-0.6106729210960264\n",
      "Gradient Descent(194/199): ||gradient||=0.016545311030577412, loss=0.3755926910253041, w0=0.08141711577151617, w1=-0.6106729210960264\n",
      "Gradient Descent(195/199): ||gradient||=0.016545311030577412, loss=0.3755736084999899, w0=0.08179841617225363, w1=-0.6110356901740174\n",
      "Gradient Descent(196/199): ||gradient||=0.017100034533504855, loss=0.37556434274899564, w0=0.0813233270414321, w1=-0.6117231829818586\n",
      "Gradient Descent(197/199): ||gradient||=0.03414575672935005, loss=0.37556434274899564, w0=0.0813233270414321, w1=-0.6117231829818586\n",
      "Gradient Descent(198/199): ||gradient||=0.03414575672935005, loss=0.37554725477411016, w0=0.08228859411954817, w1=-0.6120487848027445\n",
      "Gradient Descent(199/199): ||gradient||=0.03491003301262125, loss=0.37554725477411016, w0=0.08228859411954817, w1=-0.6120487848027445\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 200\n",
    "gamma = 0.0001\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "gradient_w, gradient_loss = gradient_descent(y, tX, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Stochastic gradient descent algorithm.\"\"\"\n",
    "    w = initial_w\n",
    "    loss = np.inf\n",
    "    for n_iter in range(max_iters):\n",
    "        for yn, xn in batch_iter(y, tx, batch_size):\n",
    "            g = compute_stoch_gradient(yn, xn, w)\n",
    "            new_w = w - gamma*g;\n",
    "            new_loss = compute_loss(y, tx, new_w)\n",
    "        if new_loss <= loss:\n",
    "            loss , w = new_loss , new_w\n",
    "            gamma *=1.8\n",
    "            #print(\"SGD({bi}/{ti}): loss={l} ; gamma={g}; gamma aumenta\".format(\n",
    "             # bi=n_iter, ti=max_iters - 1, l=loss, g= gamma))\n",
    "        else:\n",
    "            gamma *=0.3\n",
    "            #print(\"SGD({bi}/{ti}): loss={l} ; gamma={g}; gamma diminuisce\".format(\n",
    "             #     bi=n_iter, ti=max_iters - 1, l=loss, g= gamma))\n",
    "        print(\"SGD({bi}/{ti}): |gradient|={grad}, loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, grad=np.linalg.norm(g), l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(0/99): |gradient|=3.819894318273993, loss=0.5415004344865282, w0=0.011805540261408516, w1=-0.002686097454581817\n",
      "SGD(1/99): |gradient|=3.313465869115332, loss=0.5415004344865282, w0=0.011805540261408516, w1=-0.002686097454581817\n",
      "SGD(2/99): |gradient|=2.7465500598415247, loss=0.5231169592050283, w0=0.006188461831573778, w1=-0.003969062074416842\n",
      "SGD(3/99): |gradient|=3.2750457421264016, loss=0.49026883819335143, w0=-0.0036366473237117534, w1=-0.008645873148768043\n",
      "SGD(4/99): |gradient|=3.648974628785057, loss=0.4714873513207109, w0=-0.019703815429169942, w1=-0.026240410268246465\n",
      "SGD(5/99): |gradient|=3.4494660744980905, loss=0.4714873513207109, w0=-0.019703815429169942, w1=-0.026240410268246465\n",
      "SGD(6/99): |gradient|=3.143628555043909, loss=0.4714873513207109, w0=-0.019703815429169942, w1=-0.026240410268246465\n",
      "SGD(7/99): |gradient|=2.8915114659527927, loss=0.4714873513207109, w0=-0.019703815429169942, w1=-0.026240410268246465\n",
      "SGD(8/99): |gradient|=2.897412774883511, loss=0.4714873513207109, w0=-0.019703815429169942, w1=-0.026240410268246465\n",
      "SGD(9/99): |gradient|=2.1737890066966687, loss=0.4714443822232635, w0=-0.019904464199047903, w1=-0.02634329478613387\n",
      "SGD(10/99): |gradient|=5.937595790584886, loss=0.4709996675291747, w0=-0.019421647326106496, w1=-0.026244718166632628\n",
      "SGD(11/99): |gradient|=2.677548444145319, loss=0.47095357270473925, w0=-0.02081102663905905, w1=-0.026713517117417356\n",
      "SGD(12/99): |gradient|=12.171538978449524, loss=0.4669017373609154, w0=-0.02021290783452855, w1=-0.027149845066493348\n",
      "SGD(13/99): |gradient|=6.554489780166215, loss=0.4669017373609154, w0=-0.02021290783452855, w1=-0.027149845066493348\n",
      "SGD(14/99): |gradient|=3.1860265668993417, loss=0.46683403689113295, w0=-0.020819615275740173, w1=-0.027362200812291265\n",
      "SGD(15/99): |gradient|=4.980416065195217, loss=0.46683403689113295, w0=-0.020819615275740173, w1=-0.027362200812291265\n",
      "SGD(16/99): |gradient|=8.601456112840077, loss=0.46642613367989405, w0=-0.02032254885070125, w1=-0.027476523942035674\n",
      "SGD(17/99): |gradient|=2.507560742564985, loss=0.46642613367989405, w0=-0.02032254885070125, w1=-0.027476523942035674\n",
      "SGD(18/99): |gradient|=3.39722270862085, loss=0.46639024949469604, w0=-0.0204532765809344, w1=-0.027407190321897496\n",
      "SGD(19/99): |gradient|=5.7959604991936695, loss=0.46636056728990233, w0=-0.019964622091377646, w1=-0.02757084427383505\n",
      "SGD(20/99): |gradient|=2.6503861820488868, loss=0.46615398548810694, w0=-0.02051819888045534, w1=-0.02718188475904513\n",
      "SGD(21/99): |gradient|=4.766341850026974, loss=0.46615398548810694, w0=-0.02051819888045534, w1=-0.02718188475904513\n",
      "SGD(22/99): |gradient|=8.113459704551065, loss=0.4660904073374325, w0=-0.019901578391751246, w1=-0.027387751546646452\n",
      "SGD(23/99): |gradient|=2.1523951322923573, loss=0.4655962637317894, w0=-0.020503431962578023, w1=-0.02763510127265685\n",
      "SGD(24/99): |gradient|=2.125400495030948, loss=0.465050896308293, w0=-0.021228871282967347, w1=-0.02694446888606359\n",
      "SGD(25/99): |gradient|=2.90920195097991, loss=0.46443857876838635, w0=-0.023087142508211, w1=-0.02780799635242779\n",
      "SGD(26/99): |gradient|=3.3299678307457063, loss=0.46443857876838635, w0=-0.023087142508211, w1=-0.02780799635242779\n",
      "SGD(27/99): |gradient|=2.035550059511512, loss=0.46382531406925614, w0=-0.024134478424571018, w1=-0.028252426454319492\n",
      "SGD(28/99): |gradient|=2.3580415986033985, loss=0.463454498002539, w0=-0.025559249743730812, w1=-0.0282759613139578\n",
      "SGD(29/99): |gradient|=2.032813924807822, loss=0.4625936487580744, w0=-0.028828125817051634, w1=-0.029481363367709734\n",
      "SGD(30/99): |gradient|=2.2382793772999583, loss=0.4625936487580744, w0=-0.028828125817051634, w1=-0.029481363367709734\n",
      "SGD(31/99): |gradient|=1.8764337853530073, loss=0.4623414591560108, w0=-0.03057723228144025, w1=-0.030403073754884043\n",
      "SGD(32/99): |gradient|=1.8232787854563, loss=0.46205157824875615, w0=-0.03371482023092263, w1=-0.0319979397946591\n",
      "SGD(33/99): |gradient|=3.47991815484829, loss=0.4613252378794793, w0=-0.02254438255528187, w1=-0.03711256437853203\n",
      "SGD(34/99): |gradient|=2.6051466504383227, loss=0.4613252378794793, w0=-0.02254438255528187, w1=-0.03711256437853203\n",
      "SGD(35/99): |gradient|=3.122047619325702, loss=0.4613252378794793, w0=-0.02254438255528187, w1=-0.03711256437853203\n",
      "SGD(36/99): |gradient|=2.2102969803941135, loss=0.46103141880159887, w0=-0.023194632035417127, w1=-0.036577706438919055\n",
      "SGD(37/99): |gradient|=1.874048874756718, loss=0.46038466659937205, w0=-0.02427213706531704, w1=-0.03684812713307184\n",
      "SGD(38/99): |gradient|=2.0605893824283457, loss=0.45990233446963297, w0=-0.027233179187580878, w1=-0.03797723214509076\n",
      "SGD(39/99): |gradient|=4.445874973352969, loss=0.45990233446963297, w0=-0.027233179187580878, w1=-0.03797723214509076\n",
      "SGD(40/99): |gradient|=2.9986231336102747, loss=0.45990233446963297, w0=-0.027233179187580878, w1=-0.03797723214509076\n",
      "SGD(41/99): |gradient|=12.892590418104017, loss=0.4580599239196462, w0=-0.026000009060535678, w1=-0.03758569839571127\n",
      "SGD(42/99): |gradient|=4.933085208595288, loss=0.4580198866671206, w0=-0.024411383252656044, w1=-0.03756723828049817\n",
      "SGD(43/99): |gradient|=2.093934690011671, loss=0.457209388979194, w0=-0.025959960088391906, w1=-0.038170673039631155\n",
      "SGD(44/99): |gradient|=2.9960753128358437, loss=0.457209388979194, w0=-0.025959960088391906, w1=-0.038170673039631155\n",
      "SGD(45/99): |gradient|=2.438209540121207, loss=0.4571245240613506, w0=-0.026458422816273697, w1=-0.037946214784046806\n",
      "SGD(46/99): |gradient|=4.548454818977723, loss=0.4571245240613506, w0=-0.026458422816273697, w1=-0.037946214784046806\n",
      "SGD(47/99): |gradient|=2.492690399903696, loss=0.4571245240613506, w0=-0.026458422816273697, w1=-0.037946214784046806\n",
      "SGD(48/99): |gradient|=5.610456340644089, loss=0.45700707456700934, w0=-0.026251402891296544, w1=-0.03803981706218313\n",
      "SGD(49/99): |gradient|=3.318079123588936, loss=0.45700707456700934, w0=-0.026251402891296544, w1=-0.03803981706218313\n",
      "SGD(50/99): |gradient|=4.566336903746895, loss=0.45700707456700934, w0=-0.026251402891296544, w1=-0.03803981706218313\n",
      "SGD(51/99): |gradient|=2.6302184968784394, loss=0.45700336773487327, w0=-0.02627204818351755, w1=-0.0380443223126299\n",
      "SGD(52/99): |gradient|=4.585911442587165, loss=0.45698730432309054, w0=-0.026215919321215708, w1=-0.038060274350766095\n",
      "SGD(53/99): |gradient|=2.211072273144503, loss=0.45696654859836666, w0=-0.026284231954664526, w1=-0.03811421256649752\n",
      "SGD(54/99): |gradient|=1.9795518859859038, loss=0.4569246934038637, w0=-0.026376338993873042, w1=-0.03811185565460271\n",
      "SGD(55/99): |gradient|=2.556518850535039, loss=0.4569246934038637, w0=-0.026376338993873042, w1=-0.03811185565460271\n",
      "SGD(56/99): |gradient|=5.226010984055924, loss=0.4569246934038637, w0=-0.026376338993873042, w1=-0.03811185565460271\n",
      "SGD(57/99): |gradient|=4.042771629866015, loss=0.4569246934038637, w0=-0.026376338993873042, w1=-0.03811185565460271\n",
      "SGD(58/99): |gradient|=3.3067416727703223, loss=0.4569246934038637, w0=-0.026376338993873042, w1=-0.03811185565460271\n",
      "SGD(59/99): |gradient|=1.8323943777272642, loss=0.45692388503402925, w0=-0.0263770162421353, w1=-0.03811226028038737\n",
      "SGD(60/99): |gradient|=11.470974679830231, loss=0.4569150311644476, w0=-0.02637107439232714, w1=-0.03811067943123103\n",
      "SGD(61/99): |gradient|=3.0144147497867375, loss=0.4569150311644476, w0=-0.02637107439232714, w1=-0.03811067943123103\n",
      "SGD(62/99): |gradient|=3.6818876157772396, loss=0.4569150311644476, w0=-0.02637107439232714, w1=-0.03811067943123103\n",
      "SGD(63/99): |gradient|=2.163572003684967, loss=0.4569148900111584, w0=-0.026371600580659144, w1=-0.038111111440099765\n",
      "SGD(64/99): |gradient|=4.289954026547787, loss=0.4569148900111584, w0=-0.026371600580659144, w1=-0.038111111440099765\n",
      "SGD(65/99): |gradient|=2.714025703840808, loss=0.45691481807419854, w0=-0.026372017508583073, w1=-0.038111186745683305\n",
      "SGD(66/99): |gradient|=6.1144593103535225, loss=0.45691481807419854, w0=-0.026372017508583073, w1=-0.038111186745683305\n",
      "SGD(67/99): |gradient|=5.47835855595733, loss=0.45691481807419854, w0=-0.026372017508583073, w1=-0.038111186745683305\n",
      "SGD(68/99): |gradient|=2.3926333231147896, loss=0.4569147993632949, w0=-0.026372062029418, w1=-0.03811123014864691\n",
      "SGD(69/99): |gradient|=3.578895865252755, loss=0.4569147993632949, w0=-0.026372062029418, w1=-0.03811123014864691\n",
      "SGD(70/99): |gradient|=1.9919780690927347, loss=0.45691478898804516, w0=-0.026372087220421152, w1=-0.03811124869164356\n",
      "SGD(71/99): |gradient|=2.987998220725619, loss=0.456914772142296, w0=-0.026372194256254262, w1=-0.03811126143458942\n",
      "SGD(72/99): |gradient|=2.6470399520361894, loss=0.456914747739093, w0=-0.026372328513162742, w1=-0.03811127085851918\n",
      "SGD(73/99): |gradient|=2.6022737766902844, loss=0.45691470424649516, w0=-0.026372500639405515, w1=-0.0381114386159908\n",
      "SGD(74/99): |gradient|=4.187131906617635, loss=0.45691470424649516, w0=-0.026372500639405515, w1=-0.0381114386159908\n",
      "SGD(75/99): |gradient|=2.015576101474963, loss=0.45691466217210414, w0=-0.026372580731252444, w1=-0.038111478596163824\n",
      "SGD(76/99): |gradient|=2.860467748289693, loss=0.45691466217210414, w0=-0.026372580731252444, w1=-0.038111478596163824\n",
      "SGD(77/99): |gradient|=4.06415115563897, loss=0.45691465332672976, w0=-0.02637251625322853, w1=-0.03811148912062281\n",
      "SGD(78/99): |gradient|=2.4510072413307586, loss=0.4569146301993595, w0=-0.026372590750361666, w1=-0.038111538135083084\n",
      "SGD(79/99): |gradient|=3.826423961329138, loss=0.4569146301993595, w0=-0.026372590750361666, w1=-0.038111538135083084\n",
      "SGD(80/99): |gradient|=2.74372652321718, loss=0.4569146301993595, w0=-0.026372590750361666, w1=-0.038111538135083084\n",
      "SGD(81/99): |gradient|=5.885837597513265, loss=0.4569146301993595, w0=-0.026372590750361666, w1=-0.038111538135083084\n",
      "SGD(82/99): |gradient|=4.653513935748076, loss=0.4569146283558581, w0=-0.026372584040386265, w1=-0.038111541406140904\n",
      "SGD(83/99): |gradient|=2.989275111376364, loss=0.4569146283558581, w0=-0.026372584040386265, w1=-0.038111541406140904\n",
      "SGD(84/99): |gradient|=1.938495142487275, loss=0.45691462715299336, w0=-0.026372586115793333, w1=-0.03811154269589085\n",
      "SGD(85/99): |gradient|=4.135621499992417, loss=0.45691462715299336, w0=-0.026372586115793333, w1=-0.03811154269589085\n",
      "SGD(86/99): |gradient|=8.998813146377053, loss=0.45691462517922826, w0=-0.02637258430471322, w1=-0.03811154343460073\n",
      "SGD(87/99): |gradient|=6.338983621184608, loss=0.4569146227568537, w0=-0.026372581103101932, w1=-0.03811154506135068\n",
      "SGD(88/99): |gradient|=24.4524925542933, loss=0.4569146111727842, w0=-0.02637251601434, w1=-0.038111548466985015\n",
      "SGD(89/99): |gradient|=3.656262524412902, loss=0.4569146111727842, w0=-0.02637251601434, w1=-0.038111548466985015\n",
      "SGD(90/99): |gradient|=2.87088407305221, loss=0.4569146111727842, w0=-0.02637251601434, w1=-0.038111548466985015\n",
      "SGD(91/99): |gradient|=7.309979979904143, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(92/99): |gradient|=3.2762100650218438, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(93/99): |gradient|=3.1031068732380334, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(94/99): |gradient|=3.610075038327429, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(95/99): |gradient|=3.3793881254517495, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(96/99): |gradient|=2.942350120659295, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(97/99): |gradient|=5.18818024609198, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(98/99): |gradient|=4.0703048291822475, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n",
      "SGD(99/99): |gradient|=2.903848600170023, loss=0.45691461075013645, w0=-0.026372514903032197, w1=-0.03811154805088536\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "\n",
    "# Start SGD.\n",
    "sgd_loss, sgd_w = stochastic_gradient_descent(\n",
    "    y, tX, w_initial, batch_size, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    D = tx.shape[1]\n",
    "    G = tx.T.dot(tx)\n",
    "    if(np.linalg.matrix_rank(G)==D):\n",
    "        w = np.linalg.inv(G).dot(tx.T).dot(y)\n",
    "    else:\n",
    "        w = np.linalg.lstsq(G,tx.T.dot(y), rcond=None) [0]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34673788750013346"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ls = least_squares(y, tX)\n",
    "loss = compute_loss(y, tX, w_ls)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3135299879473527 0.31508110848941073 0.7918711864278845 0.7938275738337774\n"
     ]
    }
   ],
   "source": [
    "x_tr_poly = build_poly(x_tr, 4)\n",
    "x_te_poly = build_poly(x_te, 4)\n",
    "w_ls = least_squares(y_tr, x_tr_poly)\n",
    "loss_tr = compute_loss(y_tr, x_tr_poly, w_ls)\n",
    "loss_te = compute_loss(y_te, x_te_poly, w_ls)\n",
    "rmse_te = compute_rmse(y_te, x_te_poly, w_ls)\n",
    "rmse_tr = compute_rmse(y_tr, x_tr_poly, w_ls)\n",
    "print(loss_tr, loss_te, rmse_tr, rmse_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    N = len(y)\n",
    "    G = tx.T.dot(tx)\n",
    "    i = np.linalg.inv(G + 2*N*lambda_*np.eye(G.shape[0]))\n",
    "    w_star = i.dot(tx.T).dot(y)\n",
    "    return w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for jet in range(0,4):\n",
    "    x_tr, x_te, y_tr, y_te = split_data(y_new[jet],tX_new[jet],0.8,1)\n",
    "    w.append(ridge_regression(y_tr, x_tr, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24510851416621188 1026200624535.4009 0.7001550030760502 1432620.4134629667\n"
     ]
    }
   ],
   "source": [
    "x_tr_poly = build_poly(x_tr, 7)\n",
    "x_te_poly = build_poly(x_te, 7)\n",
    "lambda_ = 0.00001\n",
    "w = ridge_regression(y_tr, x_tr_poly, lambda_)\n",
    "loss_tr = compute_loss(y_tr, x_tr_poly, w)\n",
    "loss_te = compute_loss(y_te, x_te_poly, w)\n",
    "rmse_te = compute_rmse(y_te, x_te_poly, w)\n",
    "rmse_tr = compute_rmse(y_tr, x_tr_poly, w)\n",
    "print(loss_tr, loss_te, rmse_tr, rmse_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2891950223111849 0.2942724952626915 0.7605195885855733 0.7671668596370564\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.001\n",
    "w = ridge_regression(y_tr, x_tr, lambda_)\n",
    "loss_tr = compute_loss(y_tr, x_tr, w)\n",
    "loss_te = compute_loss(y_te, x_te, w)\n",
    "rmse_te = compute_rmse(y_te, x_te, w)\n",
    "rmse_tr = compute_rmse(y_tr, x_tr, w)\n",
    "print(loss_tr, loss_te, rmse_tr, rmse_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Accuracy and F1 Score on our classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(250000)\n",
    "for jet in range (0,4):\n",
    "    y_p = predict_labels(w[jet], tX_new[jet])\n",
    "    index = ids[jet]\n",
    "    y_pred[index] = y_p\n",
    "_, _, _, y_te = split_data(y, tX, 0.8, 1)\n",
    "_, _, _, y_pred_test = split_data(y_pred, tX, 0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7473 0.5535493445461291\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_te, y_pred_test)\n",
    "f1 = f1_score(y_te, y_pred_test)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790336 0.6746611053180397\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict_labels(w, x_te_poly)\n",
    "acc = accuracy_score(y_te, y_pred_test)\n",
    "f1 = f1_score(y_te, y_pred_test)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "tX_test_s, mean_tes, std_test = standardize(tX_test)\n",
    "y_pred = predict_labels(w, tX_test_s)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tX_test_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-794235a07782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprincipalComponents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_test_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprincipalComponents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprincipalComponents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tX_test_s' is not defined"
     ]
    }
   ],
   "source": [
    "#we will need something like this\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(tX_test_s)\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
