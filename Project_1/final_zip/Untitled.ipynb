{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from implementations import reg_logistic_regression\n",
    "from implementation_helpers import calculate_loss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "y_or, tX_or, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_or\n",
    "tX = tX_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = pd.DataFrame(tX)\n",
    "tX.where(tX!=-999, inplace=True)\n",
    "tX.fillna(tX.median(), inplace=True)    \n",
    "tX = tX.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_for_logistic(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_tot, x_te_tot, y_tr_tot, y_te_tot = split_data(y,tX,0.8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-373960a6829b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr_tot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tr_tot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'logistic_regression' is not defined"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(x_tr_tot.shape[1])\n",
    "max_iters = 10000\n",
    "gamma = 1e-10\n",
    "w, loss = logistic_regression(y_tr_tot, x_tr_tot, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, tx_te_tot, True)\n",
    "acc = accuracy(y_te_tot, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=121300.75659799043\n",
      "Current iteration=1000, loss=93581.46043394844\n",
      "Current iteration=2000, loss=93239.80127423578\n",
      "Current iteration=3000, loss=93127.35430130895\n",
      "Current iteration=4000, loss=93077.86977980098\n",
      "Current iteration=5000, loss=93052.77794496421\n",
      "Current iteration=6000, loss=93038.0524237295\n",
      "Current iteration=7000, loss=93027.87325478229\n",
      "Current iteration=8000, loss=93019.71926021982\n",
      "Current iteration=9000, loss=93012.4799203386\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(x_tr_tot.shape[1])\n",
    "lambda_ = 1e-8\n",
    "max_iters = 10000\n",
    "gamma = 1e-10\n",
    "w, loss = reg_logistic_regression(y_tr_tot, x_tr_tot, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7349466666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_labels(w, x_te_tot, True)\n",
    "acc = accuracy(y_te_tot, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, gamma, acc = False, ls = False):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    losses_tr = []\n",
    "    losses_te = []\n",
    "    accuracies = []\n",
    "    ws = []\n",
    "    initial_w = np.zeros(x.shape[1])\n",
    "\n",
    "    \n",
    "    for k_group in range(k):\n",
    "        index_te = k_indices[k_group]\n",
    "        index_tr = np.setdiff1d(np.arange(len(y)), index_te)\n",
    "        #print(index_te, index_tr)\n",
    "        x_te = x[index_te]\n",
    "        x_tr = x[index_tr]\n",
    "        y_te = y[index_te]\n",
    "        y_tr = y[index_tr]\n",
    "        \n",
    "        # form data with polynomial degree\n",
    "        x_te_poly = x_te\n",
    "        x_tr_poly = x_tr\n",
    "        \n",
    "        if (ls==False):\n",
    "            w, _ = reg_logistic_regression(y_tr, x_tr_poly, lambda_, initial_w, 1000, gamma)\n",
    "        else:\n",
    "            w = least_squares_lstsq_ver(y_tr, x_tr_poly)\n",
    "        \n",
    "        # calculate the loss for train and test data\n",
    "        rmse_tr = calculate_loss(y_tr, x_tr_poly, w)\n",
    "        rmse_te = calculate_loss(y_te, x_te_poly, w)\n",
    "        #print(lambda_, rmse_te)\n",
    "        losses_tr.append(rmse_tr)\n",
    "        losses_te.append(rmse_te)\n",
    "        \n",
    "        y_pred = predict_labels(w, x_te_poly)\n",
    "        accuracies.append(accuracy(y_te, y_pred))\n",
    "        \n",
    "        ws.append(w)\n",
    "        \n",
    "    if acc==False:\n",
    "        loss_tr = np.median(losses_tr)\n",
    "        loss_te = np.median(losses_te)\n",
    "        return loss_tr, loss_te, np.mean(ws, axis=0)\n",
    "    else:\n",
    "        return np.mean(accuracies), np.mean(ws, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_hypers(y, x, k_fold, seed=1):\n",
    "    #y_sub, x_sub = get_subsample(y, x, 100000, seed)\n",
    "    lambdas = np.logspace(-8, 0, 8)\n",
    "    gammas = np.logspace(-6, 0, 5)\n",
    "    #lambdas=[1e-06]\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    loss_min = np.inf\n",
    "    gamma_star = 0\n",
    "    lambda_star = 0\n",
    "    w_star = 0\n",
    "    for gamma in gammas:\n",
    "        for lambda_ in lambdas:\n",
    "            #print(degree)\n",
    "            loss_tr, loss_te, w = cross_validation(y, x, k_indices, k_fold, lambda_, gamma)\n",
    "            #print(loss_te)\n",
    "            if loss_te < loss_min:\n",
    "                loss_min = loss_te\n",
    "                print(\"New loss: {}, gamma: {}, lambda: {}\".format(loss_te, gamma, lambda_))\n",
    "                gamma_star = gamma\n",
    "                lambda_star = lambda_\n",
    "                w_star = w\n",
    "    return gamma_star, lambda_star, loss_min, w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet 0: \n",
      "New loss: 1223.9791281210773, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 936.8265655823413, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 0: best loss: 936.8265655823413, degree: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 1: \n",
      "New loss: 8487.580246188481, gamma: 1e-06, lambda: 1e-08\n",
      "jet 1: best loss: 8487.580246188481, degree: 1e-06, lambda: 1e-08\n",
      "jet 2: \n",
      "New loss: 476.60760865688735, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 418.492834146361, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 2: best loss: 418.492834146361, degree: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 3: \n",
      "New loss: 8371.862932929653, gamma: 1e-06, lambda: 1e-08\n"
     ]
    }
   ],
   "source": [
    "k_fold = 4\n",
    "gammas_star=[]\n",
    "lambdas_star=[]\n",
    "w_star = []\n",
    "for jet in range(0, 8):\n",
    "    print(\"jet {}: \".format(jet))\n",
    "    gamma_star, lambda_star, loss, w = select_best_hypers(y_tr[jet], tX_tr[jet], k_fold, 1)\n",
    "    gammas_star.append(gamma_star)\n",
    "    lambdas_star.append(lambda_star)\n",
    "    w_star.append(w)\n",
    "    #print(\"jet {}: Best accuracy {}, degree: {},  lambda: {}\".format(jet, acc, degree_star, lambda_star))\n",
    "    print(\"jet {}: best loss: {}, degree: {}, lambda: {}\".format(jet, loss, gamma_star, lambda_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, tX_tr, indexes_tr, means_tr, std_tr = preprocessing(x_tr_tot, y_tr_tot)\n",
    "y_te, tX_te, indexes_te, means_te, std_te = preprocessing(x_te_tot, y_te_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
