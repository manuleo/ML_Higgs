{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "y_or, tX_or, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_or\n",
    "tX = tX_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = pd.DataFrame(tX)\n",
    "tX.where(tX!=-999, inplace=True)\n",
    "tX.fillna(tX.median(), inplace=True)    \n",
    "tX = tX.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_for_logistic(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_tot, x_te_tot, y_tr_tot, y_te_tot = split_data(y,tX,0.8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=138629.43611198905\n",
      "Current iteration=1000, loss=106751.60151235267\n",
      "Current iteration=2000, loss=106408.02717390667\n",
      "Current iteration=3000, loss=106299.1933633236\n",
      "Current iteration=4000, loss=106253.50135402067\n",
      "Current iteration=5000, loss=106230.50607151032\n",
      "Current iteration=6000, loss=106216.27284014336\n",
      "Current iteration=7000, loss=106205.50922362538\n",
      "Current iteration=8000, loss=106196.14474365817\n",
      "Current iteration=9000, loss=106187.35953373656\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(x_tr_tot.shape[1])\n",
    "max_iters = 10000\n",
    "gamma = 1e-10\n",
    "w, loss = logistic_regression(y_tr_tot, x_tr_tot, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7362\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_labels(w, x_te_tot, True)\n",
    "acc = accuracy(y_te_tot, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for logistic\n",
    "y_pred_test = predict_labels(w, tX_test, True)\n",
    "OUTPUT_PATH = 'submission.csv'\n",
    "create_csv_submission(ids_test, y_pred_test, OUTPUT_PATH, logistic=True) #logistic flags convert [0, 1] to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=134001.19392646643\n",
      "Current iteration=1000, loss=106750.92508967363\n",
      "Current iteration=2000, loss=106407.85577669005\n",
      "Current iteration=3000, loss=106299.12698797951\n",
      "Current iteration=4000, loss=106253.47056667147\n",
      "Current iteration=5000, loss=106230.48878656604\n",
      "Current iteration=6000, loss=106216.26085869093\n",
      "Current iteration=7000, loss=106205.49936369108\n",
      "Current iteration=8000, loss=106196.13575003046\n",
      "Current iteration=9000, loss=106187.3509072507\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(x_tr_tot.shape[1])\n",
    "lambda_ = 1e-8\n",
    "max_iters = 10000\n",
    "gamma = 1e-10\n",
    "w, loss = reg_logistic_regression(y_tr_tot, x_tr_tot, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7362\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_labels(w, x_te_tot, True)\n",
    "acc = accuracy(y_te_tot, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for logistic\n",
    "y_pred_test = predict_labels(w, tX_test, True)\n",
    "OUTPUT_PATH = 'submission.csv'\n",
    "create_csv_submission(ids_test, y_pred_test, OUTPUT_PATH, logistic=True) #logistic flags convert [0, 1] to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, gamma, acc = False, ls = False):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    losses_tr = []\n",
    "    losses_te = []\n",
    "    accuracies = []\n",
    "    ws = []\n",
    "    initial_w = np.zeros(x.shape[1])\n",
    "\n",
    "    \n",
    "    for k_group in range(k):\n",
    "        index_te = k_indices[k_group]\n",
    "        index_tr = np.setdiff1d(np.arange(len(y)), index_te)\n",
    "        #print(index_te, index_tr)\n",
    "        x_te = x[index_te]\n",
    "        x_tr = x[index_tr]\n",
    "        y_te = y[index_te]\n",
    "        y_tr = y[index_tr]\n",
    "        \n",
    "        # form data with polynomial degree\n",
    "        x_te_poly = x_te\n",
    "        x_tr_poly = x_tr\n",
    "        \n",
    "        if (ls==False):\n",
    "            w, _ = reg_logistic_regression(y_tr, x_tr_poly, lambda_, initial_w, 1000, gamma)\n",
    "        else:\n",
    "            w = least_squares_lstsq_ver(y_tr, x_tr_poly)\n",
    "        \n",
    "        # calculate the loss for train and test data\n",
    "        rmse_tr = calculate_loss(y_tr, x_tr_poly, w)\n",
    "        rmse_te = calculate_loss(y_te, x_te_poly, w)\n",
    "        #print(lambda_, rmse_te)\n",
    "        losses_tr.append(rmse_tr)\n",
    "        losses_te.append(rmse_te)\n",
    "        \n",
    "        y_pred = predict_labels(w, x_te_poly)\n",
    "        accuracies.append(accuracy(y_te, y_pred))\n",
    "        \n",
    "        ws.append(w)\n",
    "        \n",
    "    if acc==False:\n",
    "        loss_tr = np.median(losses_tr)\n",
    "        loss_te = np.median(losses_te)\n",
    "        return loss_tr, loss_te, np.mean(ws, axis=0)\n",
    "    else:\n",
    "        return np.mean(accuracies), np.mean(ws, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_hypers(y, x, k_fold, seed=1):\n",
    "    #y_sub, x_sub = get_subsample(y, x, 100000, seed)\n",
    "    lambdas = np.logspace(-8, 0, 8)\n",
    "    gammas = np.logspace(-6, 0, 5)\n",
    "    #lambdas=[1e-06]\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    loss_min = np.inf\n",
    "    gamma_star = 0\n",
    "    lambda_star = 0\n",
    "    w_star = 0\n",
    "    for gamma in gammas:\n",
    "        for lambda_ in lambdas:\n",
    "            #print(degree)\n",
    "            loss_tr, loss_te, w = cross_validation(y, x, k_indices, k_fold, lambda_, gamma)\n",
    "            #print(loss_te)\n",
    "            if loss_te < loss_min:\n",
    "                loss_min = loss_te\n",
    "                print(\"New loss: {}, gamma: {}, lambda: {}\".format(loss_te, gamma, lambda_))\n",
    "                gamma_star = gamma\n",
    "                lambda_star = lambda_\n",
    "                w_star = w\n",
    "    return gamma_star, lambda_star, loss_min, w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet 0: \n",
      "New loss: 1223.9791281210773, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 936.8265655823413, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 0: best loss: 936.8265655823413, degree: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 1: \n",
      "New loss: 8487.580246188481, gamma: 1e-06, lambda: 1e-08\n",
      "jet 1: best loss: 8487.580246188481, degree: 1e-06, lambda: 1e-08\n",
      "jet 2: \n",
      "New loss: 476.60760865688735, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 418.492834146361, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 2: best loss: 418.492834146361, degree: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 3: \n",
      "New loss: 8371.862932929653, gamma: 1e-06, lambda: 1e-08\n",
      "jet 3: best loss: 8371.862932929653, degree: 1e-06, lambda: 1e-08\n",
      "jet 4: \n",
      "New loss: 253.43329536578767, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 246.94184229189779, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 4: best loss: 246.94184229189779, degree: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 5: \n",
      "New loss: 6504.6613494500925, gamma: 1e-06, lambda: 1e-08\n",
      "jet 5: best loss: 6504.6613494500925, degree: 1e-06, lambda: 1e-08\n",
      "jet 6: \n",
      "New loss: 80.44961400339051, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 77.3968062442509, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "New loss: 71.3832409208429, gamma: 0.001, lambda: 1e-08\n",
      "jet 6: best loss: 71.3832409208429, degree: 0.001, lambda: 1e-08\n",
      "jet 7: \n",
      "New loss: 2448.3756569733373, gamma: 1e-06, lambda: 1e-08\n",
      "New loss: 2305.0375541334847, gamma: 3.1622776601683795e-05, lambda: 1e-08\n",
      "jet 7: best loss: 2305.0375541334847, degree: 3.1622776601683795e-05, lambda: 1e-08\n"
     ]
    }
   ],
   "source": [
    "k_fold = 4\n",
    "gammas_star=[]\n",
    "lambdas_star=[]\n",
    "w_star = []\n",
    "for jet in range(0, 8):\n",
    "    print(\"jet {}: \".format(jet))\n",
    "    gamma_star, lambda_star, loss, w = select_best_hypers(y_tr[jet], tX_tr[jet], k_fold, 1)\n",
    "    gammas_star.append(gamma_star)\n",
    "    lambdas_star.append(lambda_star)\n",
    "    w_star.append(w)\n",
    "    #print(\"jet {}: Best accuracy {}, degree: {},  lambda: {}\".format(jet, acc, degree_star, lambda_star))\n",
    "    print(\"jet {}: best loss: {}, degree: {}, lambda: {}\".format(jet, loss, gamma_star, lambda_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, tX_tr, indexes_tr, means_tr, std_tr = preprocessing(x_tr_tot, y_tr_tot)\n",
    "y_te, tX_te, indexes_te, means_te, std_te = preprocessing(x_te_tot, y_te_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_loss = []\n",
    "list_w = []\n",
    "for jet in range(0,8):\n",
    "    initial_w = np.zeros(tX_tr[jet].shape[1])\n",
    "    w, loss = reg_logistic_regression(y_tr[jet], tX_tr[jet], lambdas_star[jet], initial_w, 10000, gammas_star[jet])\n",
    "    list_loss.append(loss)\n",
    "    list_w.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72788\n"
     ]
    }
   ],
   "source": [
    "#cell for logistic\n",
    "y_pred = build_predictions(tX_te, indexes_te, list_w, logistic=True) \n",
    "acc = accuracy(y_te_tot, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 1e-08, 1e-08, 1e-08, 1e-08, 1e-08, 1e-08, 1e-08]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test_new, indexes_test_new, means_test, stds_test = preprocessing(tX_test) #same function as train,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for logistic\n",
    "y_pred_test = build_predictions(tX_test_new, indexes_test_new, list_w, logistic=True)\n",
    "OUTPUT_PATH = 'submission.csv'\n",
    "create_csv_submission(ids_test, y_pred_test, OUTPUT_PATH, logistic=True) #logistic flags convert [0, 1] to [-1, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
